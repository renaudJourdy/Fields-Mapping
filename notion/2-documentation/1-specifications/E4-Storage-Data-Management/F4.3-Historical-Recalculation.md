**Epic:** E4 â€“ Storage & Data Management  
**Depends on:** E1 (cold storage), E2 (transformation pipeline), E4 (warm storage)  
**Related Features:** F4.2 (Store to Warm Storage)

---

## 1. Description

Reprocess historical raw packets from cold storage with new transformation rules to compute newly added Fleeti fields. Enables complete historical data for new fields without gaps.

### 1.1 Purpose

When new Fleeti fields are added, customers must have complete historical data for those fields. Historical recalculation reprocesses old raw packets with new transformation rules to compute new fields.

### 1.2 Context

When new fields are added to Fleeti telemetry schema, existing historical data doesn't include those fields. Historical recalculation scans cold storage, reprocesses packets with new rules, and updates warm storage.

### 1.3 Value Proposition

Ensures customers have complete historical data for new fields without gaps. Critical for data completeness and customer satisfaction.

---

## 2. Business Logic

### 2.1 Rules & Priority

**Recalculation Triggers:**
- New Fleeti fields added to schema
- New transformation rules added
- Mapping rules updated

**Recalculation Process:**
1. Identify time range for recalculation
2. Load raw packets from cold storage
3. Apply new transformation rules (Epic 2)
4. Compute new fields
5. Update warm storage with new fields

**Recalculation Scope:**
- All assets or specific assets
- Time range: From field addition date backwards
- Batch processing for efficiency

### 2.2 States & Behaviors

**Recalculation States:**
- **Queued**: Recalculation job queued
- **Processing**: Recalculation in progress
- **Completed**: Recalculation finished successfully
- **Failed**: Recalculation failed, retry or manual intervention

**Behaviors:**
- Background processing (non-blocking)
- Progress tracking and reporting
- Resume capability for interrupted jobs

### 2.3 Edge Cases

- **Large Time Ranges**: Process in batches
- **Missing Raw Packets**: Skip or log warning
- **Transformation Failures**: Log and continue
- **Storage Failures**: Retry with backoff

---

## 3. Technical Specification

### 3.1 Inputs

- **Raw Packets**: From cold storage (Epic 1)
- **New Transformation Rules**: From Epic 2
- **Time Range**: Start and end timestamps
- **Asset IDs**: Specific assets or all assets

### 3.2 Processing Logic

1. Identify recalculation scope (time range, assets)
2. Load raw packets from cold storage
3. Apply new transformation rules (Epic 2 pipeline)
4. Compute new fields
5. Update warm storage with new fields
6. Track progress and handle failures

### 3.3 Outputs

- **Recalculation Result**: Success/failure
- **Progress Report**: Assets processed, time range covered
- **Updated Warm Storage**: New fields added to historical data

### 3.4 Data Structures

```json
{
  "recalculation_id": "uuid",
  "status": "processing",
  "progress": {
    "assets_processed": 100,
    "total_assets": 1000,
    "time_range": { "start": "...", "end": "..." }
  }
}
```

---

## 4. Integration & Contracts

### 4.3 External Service Integration

**Service:** Cold Storage (Epic 1)  
**Integration Type:** Storage API read  
**Usage:** Load raw packets for reprocessing

**Service:** Transformation Pipeline (Epic 2)  
**Integration Type:** Internal pipeline  
**Usage:** Apply new transformation rules

**Service:** Warm Storage (F4.2)  
**Integration Type:** Storage API write  
**Usage:** Update historical data with new fields

---

## 5. Cross-Cutting Concerns

### 5.3 Error Handling

**Reference:** [`../../5-operations/error-handling.md`](../../5-operations/error-handling.md)

Recalculation failures should be logged and retried. See error handling documentation.

### 5.4 Monitoring & Observability

**Reference:** [`../../5-operations/monitoring-observability.md`](../../5-operations/monitoring-observability.md)

Must emit metrics: `telemetry.recalculation.jobs`, `telemetry.recalculation.progress`, `telemetry.recalculation.errors`. See monitoring documentation.

---

## 6. Acceptance Criteria

### AC1 â€“ Reprocess Historical Packets

**Given** new fields are added and raw packets exist  
**When** recalculation is triggered  
**Then** historical packets are reprocessed with new rules

### AC2 â€“ Update Warm Storage

**Given** recalculation completes  
**When** new fields are computed  
**Then** warm storage is updated with new fields

### AC3 â€“ Track Progress

**Given** recalculation is running  
**When** checking status  
**Then** progress is reported accurately

---

## 7. Performance Requirements

- **Throughput:** Process historical data efficiently
- **Batch Size:** Optimal batch size for processing
- **Resume Capability:** Resume interrupted jobs

---

## 8. Testing Strategy

### 8.1 Unit Tests

- Recalculation job creation
- Packet reprocessing logic
- Progress tracking

### 8.2 Integration Tests

- End-to-end recalculation with test data
- Cold storage integration
- Warm storage updates

---

## 9. References

### 9.1 Related Documentation

- **[Epic 4 Overview](./README.md)**: Epic context
- **[ðŸ“¥ Epic 1 - Ingestion](../E1-Ingestion-Provider-Integration/README.md)**: Cold storage
- **[ðŸ”„ Epic 2 - Field Mapping](../E2-Field-Mapping-Transformation/README.md)**: Transformation pipeline

---

## 10. Non-Goals

- Field mapping (covered by Epic 2)
- Storage operations (covered by F4.1, F4.2)

---

## 11. Open Questions

1. How should recalculation be triggered?
2. What is the optimal batch size?
3. How should progress be reported?

---

## 12. Change History

| Date | Version | Author | Changes |
|------|---------|--------|---------|
| 2025-01-XX | 1.0 | [Author] | Initial feature specification |

